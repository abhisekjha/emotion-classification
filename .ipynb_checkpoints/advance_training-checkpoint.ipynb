{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b46bf37e-9b24-4c84-abcd-714013c3f687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal MSE: 2.3799780269549164e-06\n",
      "Valence MSE: 2.3049860974728187e-05\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import joblib\n",
    "\n",
    "# # Load arousal and valence data\n",
    "# arousal_df = pd.read_csv('./data/annotations/arousal.csv')\n",
    "# valence_df = pd.read_csv('./data/annotations/valence.csv')\n",
    "\n",
    "# # Compute labels as mean values across columns\n",
    "# y_arousal = arousal_df.iloc[:, 1:].mean(axis=1).values\n",
    "# y_valence = valence_df.iloc[:, 1:].mean(axis=1).values\n",
    "\n",
    "# # Extract statistical features from arousal and valence data\n",
    "# def extract_features_from_csv(arousal_df, valence_df):\n",
    "#     features = []\n",
    "#     for i in range(len(arousal_df)):\n",
    "#         arousal_row = arousal_df.iloc[i, 1:]  # Skip index column\n",
    "#         valence_row = valence_df.iloc[i, 1:]\n",
    "        \n",
    "#         # Statistical features: mean, std deviation, and median for each row\n",
    "#         arousal_mean = arousal_row.mean()\n",
    "#         arousal_std = arousal_row.std()\n",
    "#         arousal_median = arousal_row.median()\n",
    "        \n",
    "#         valence_mean = valence_row.mean()\n",
    "#         valence_std = valence_row.std()\n",
    "#         valence_median = valence_row.median()\n",
    "        \n",
    "#         # Combine features into a single list for the row\n",
    "#         features.append([arousal_mean, arousal_std, arousal_median,\n",
    "#                          valence_mean, valence_std, valence_median])\n",
    "#     return np.array(features)\n",
    "\n",
    "# # Generate feature matrix\n",
    "# X = extract_features_from_csv(arousal_df, valence_df)\n",
    "\n",
    "# # Split data into training and testing sets\n",
    "# X_train, X_test, y_train_arousal, y_test_arousal = train_test_split(X, y_arousal, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train_valence, y_test_valence = train_test_split(X, y_valence, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train Random Forest models for arousal and valence\n",
    "# rf_arousal = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
    "# rf_arousal.fit(X_train, y_train_arousal)\n",
    "\n",
    "# rf_valence = RandomForestRegressor(n_estimators=200, max_depth=15, random_state=42)\n",
    "# rf_valence.fit(X_train, y_train_valence)\n",
    "\n",
    "# # Evaluate models\n",
    "# arousal_pred = rf_arousal.predict(X_test)\n",
    "# valence_pred = rf_valence.predict(X_test)\n",
    "# arousal_mse = mean_squared_error(y_test_arousal, arousal_pred)\n",
    "# valence_mse = mean_squared_error(y_test_valence, valence_pred)\n",
    "\n",
    "# # Save the trained models\n",
    "# joblib.dump(rf_arousal, \"./model/rf_arousal_model_statistical.pkl\")\n",
    "# joblib.dump(rf_valence, \"./model/rf_valence_model_statistical.pkl\")\n",
    "\n",
    "# print(f\"Arousal MSE: {arousal_mse}\")\n",
    "# print(f\"Valence MSE: {valence_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fba69297-a9bc-449f-91b4-ee0a9697c74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/song_feature_summary.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the folder containing the CSV files\n",
    "folder_path = './data/features'\n",
    "summary_data = []\n",
    "\n",
    "# List of audio features to extract\n",
    "features_to_extract = [\n",
    "    'pcm_RMSenergy_sma_stddev', 'pcm_RMSenergy_sma_amean', \n",
    "    'pcm_zcr_sma', \n",
    "    'F0final_sma_stddev', 'F0final_sma_amean', \n",
    "    'voicingFinalUnclipped_sma_stddev', 'voicingFinalUnclipped_sma_amean', \n",
    "    'pcm_fftMag_spectralCentroid_sma_stddev', 'pcm_fftMag_spectralCentroid_sma_amean',\n",
    "    'pcm_fftMag_spectralFlux_sma_stddev', 'pcm_fftMag_spectralFlux_sma_amean', \n",
    "    'pcm_fftMag_spectralRollOff50.0_sma_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_amean',\n",
    "    'pcm_fftMag_spectralRollOff75.0_sma_stddev', 'pcm_fftMag_spectralRollOff75.0_sma_amean'\n",
    "]\n",
    "# Add MFCC columns (1-14)\n",
    "mfcc_columns = [f'pcm_fftMag_mfcc_sma[{i}]' for i in range(1, 15)]\n",
    "features_to_extract.extend(mfcc_columns)\n",
    "\n",
    "# Loop through each CSV file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Define full path to the file\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Load the CSV file with semicolon delimiter\n",
    "        data = pd.read_csv(file_path, delimiter=';')\n",
    "        \n",
    "        # Check for the presence of required columns\n",
    "        existing_features = [col for col in features_to_extract if col in data.columns]\n",
    "        if not existing_features:\n",
    "            continue  # Skip files without the required columns\n",
    "        \n",
    "        # Calculate the mean of each required feature\n",
    "        mean_values = data[existing_features].mean()\n",
    "        \n",
    "        # Extract the song ID from the filename (e.g., 2.csv -> 2)\n",
    "        song_id = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # Append the results to the summary data\n",
    "        summary_data.append({\n",
    "            'song_id': song_id,\n",
    "            **mean_values.to_dict()\n",
    "        })\n",
    "\n",
    "# Create a DataFrame for the summary data\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Export the summary data to a new CSV file\n",
    "output_path = './data/song_feature_summary.csv'\n",
    "summary_df.to_csv(output_path, index=False)\n",
    "\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de5bb96-3196-40e9-ab36-f9c69eefa6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal MSE: 1.7755632158335745e-06, Valence MSE: 2.629039304072633e-05\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "# import joblib\n",
    "\n",
    "# # Load the arousal and valence CSV files\n",
    "# arousal_df = pd.read_csv('./data/annotations/arousal.csv')\n",
    "# valence_df = pd.read_csv('./data/annotations/valence.csv')\n",
    "\n",
    "# # Define a function to compute summary statistics for each song\n",
    "# def extract_summary_statistics(df):\n",
    "#     # Initialize lists to store features\n",
    "#     features = []\n",
    "#     for _, row in df.iterrows():\n",
    "#         # Calculate statistics for arousal or valence\n",
    "#         mean_val = np.mean(row[1:])\n",
    "#         median_val = np.median(row[1:])\n",
    "#         std_val = np.std(row[1:])\n",
    "#         max_val = np.max(row[1:])\n",
    "#         min_val = np.min(row[1:])\n",
    "        \n",
    "#         # Combine all statistics into a single feature vector for this song\n",
    "#         features.append([mean_val, median_val, std_val, max_val, min_val])\n",
    "#     return np.array(features)\n",
    "\n",
    "# # Extract features for arousal and valence\n",
    "# X_arousal = extract_summary_statistics(arousal_df)\n",
    "# X_valence = extract_summary_statistics(valence_df)\n",
    "\n",
    "# # Combine arousal and valence features into a single feature matrix for training\n",
    "# X = np.hstack([X_arousal, X_valence])\n",
    "\n",
    "# # Labels for arousal and valence (mean values across timestamps)\n",
    "# y_arousal = arousal_df.iloc[:, 1:].mean(axis=1).values\n",
    "# y_valence = valence_df.iloc[:, 1:].mean(axis=1).values\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train_arousal, y_test_arousal = train_test_split(X, y_arousal, test_size=0.2, random_state=42)\n",
    "# X_train, X_test, y_train_valence, y_test_valence = train_test_split(X, y_valence, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train Random Forest models for arousal and valence prediction\n",
    "# rf_arousal = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf_arousal.fit(X_train, y_train_arousal)\n",
    "\n",
    "# rf_valence = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "# rf_valence.fit(X_train, y_train_valence)\n",
    "\n",
    "# # Evaluate models using Mean Squared Error (MSE)\n",
    "# arousal_pred = rf_arousal.predict(X_test)\n",
    "# valence_pred = rf_valence.predict(X_test)\n",
    "\n",
    "# arousal_mse = mean_squared_error(y_test_arousal, arousal_pred)\n",
    "# valence_mse = mean_squared_error(y_test_valence, valence_pred)\n",
    "\n",
    "# # Save the trained models\n",
    "# joblib.dump(rf_arousal, \"./model/rf_arousal_model_summary.pkl\")\n",
    "# joblib.dump(rf_valence, \"./model/rf_valence_model_summary.pkl\")\n",
    "\n",
    "# print(f\"Arousal MSE: {arousal_mse}, Valence MSE: {valence_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab9b7fc-6729-4373-ab52-60e4390eba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/song_arousal_summary.csv', './data/song_valence_summary.csv')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the combined song feature summary CSV file\n",
    "summary_df = pd.read_csv('./data/song_feature_summary.csv')\n",
    "\n",
    "# Define feature sets for arousal and valence\n",
    "arousal_features = [\n",
    "    'song_id',\n",
    "    'pcm_RMSenergy_sma_stddev', 'pcm_RMSenergy_sma_amean', \n",
    "    'pcm_zcr_sma', \n",
    "    'F0final_sma_stddev', 'F0final_sma_amean', \n",
    "    'voicingFinalUnclipped_sma_stddev', 'voicingFinalUnclipped_sma_amean', \n",
    "    'pcm_fftMag_spectralFlux_sma_stddev', 'pcm_fftMag_spectralFlux_sma_amean'\n",
    "]\n",
    "\n",
    "valence_features = [\n",
    "    'song_id',\n",
    "    'F0final_sma_stddev', 'F0final_sma_amean', \n",
    "    'voicingFinalUnclipped_sma_stddev', 'voicingFinalUnclipped_sma_amean', \n",
    "    'pcm_fftMag_spectralCentroid_sma_stddev', 'pcm_fftMag_spectralCentroid_sma_amean',\n",
    "    'pcm_fftMag_spectralRollOff50.0_sma_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_amean',\n",
    "    'pcm_fftMag_spectralRollOff75.0_sma_stddev', 'pcm_fftMag_spectralRollOff75.0_sma_amean'\n",
    "]\n",
    "\n",
    "# Add MFCC columns (for valence)\n",
    "mfcc_columns = [f'pcm_fftMag_mfcc_sma[{i}]' for i in range(1, 15)]\n",
    "valence_features.extend(mfcc_columns)\n",
    "\n",
    "# Filter out the arousal and valence features from the main summary DataFrame\n",
    "arousal_df = summary_df[[col for col in arousal_features if col in summary_df.columns]]\n",
    "valence_df = summary_df[[col for col in valence_features if col in summary_df.columns]]\n",
    "\n",
    "# Save the arousal and valence data to separate CSV files\n",
    "arousal_output_path = './data/song_arousal_summary.csv'\n",
    "valence_output_path = './data/song_valence_summary.csv'\n",
    "arousal_df.to_csv(arousal_output_path, index=False)\n",
    "valence_df.to_csv(valence_output_path, index=False)\n",
    "\n",
    "arousal_output_path, valence_output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce3dcb4-b13e-46a1-b2f7-2508f3388dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "48 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [-5.47119935 -6.97592841 -4.78754249         nan -7.17754105 -6.78135467\n",
      " -5.37333898 -5.8439954  -4.67860257         nan -5.51291278 -4.99054613\n",
      "         nan -7.18434189 -6.73725955         nan         nan -5.07321644\n",
      " -5.37242964 -6.78135467         nan -5.40220502 -6.79569992 -7.18434189\n",
      "         nan         nan -4.97994816 -6.41236906 -6.40793142 -6.72391228\n",
      " -6.26933856         nan -7.18434189 -4.69288625         nan         nan\n",
      " -6.78135467 -6.78135467 -5.12761761 -5.90733958 -5.87231555 -5.07321644\n",
      "         nan         nan -4.72518381 -6.78013574 -6.67448449         nan\n",
      "         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Arousal Model MSE: 1.3813981711975494, MAE: 0.6104694467139841, R²: 0.9930307608960749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
      "48 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "46 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/abhisekjha/jupyter_env/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1103: UserWarning: One or more of the test scores are non-finite: [-1086.3296218  -1266.44648461 -1028.3583098             nan\n",
      " -1268.91092073 -1195.77024592 -1089.2953195  -1189.45214291\n",
      " -1019.62292289            nan -1101.57987168 -1072.10131535\n",
      "            nan -1261.67898061 -1211.08412216            nan\n",
      "            nan -1080.89564428 -1107.62867026 -1195.77024592\n",
      "            nan -1104.90234927 -1198.76915198 -1261.67898061\n",
      "            nan            nan -1057.55337439 -1208.43591078\n",
      " -1216.2682552  -1202.70881678 -1212.0204349             nan\n",
      " -1261.67898061 -1018.46693013            nan            nan\n",
      " -1195.77024592 -1195.77024592 -1075.34467676 -1220.93927281\n",
      " -1116.63140253 -1080.89564428            nan            nan\n",
      " -1011.13907656 -1208.46008162 -1188.00092129            nan\n",
      "            nan            nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Valence Model MSE: 89.08114847965425, MAE: 5.348200080386539, R²: 0.9932305704982951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['./model/tuned_rf_valence_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Load the arousal and valence summary data\n",
    "arousal_df = pd.read_csv('./data/song_arousal_summary.csv')\n",
    "valence_df = pd.read_csv('./data/song_valence_summary.csv')\n",
    "\n",
    "# Define RFE-selected features\n",
    "arousal_features = [\n",
    "    'pcm_RMSenergy_sma_stddev', \n",
    "    'F0final_sma_stddev', \n",
    "    'F0final_sma_amean', \n",
    "    'voicingFinalUnclipped_sma_stddev', \n",
    "    'pcm_fftMag_spectralFlux_sma_amean'\n",
    "]\n",
    "valence_features = [\n",
    "    'F0final_sma_stddev', \n",
    "    'F0final_sma_amean', \n",
    "    'voicingFinalUnclipped_sma_stddev', \n",
    "    'pcm_fftMag_spectralCentroid_sma_amean', \n",
    "    'pcm_fftMag_spectralRollOff50.0_sma_stddev'\n",
    "]\n",
    "\n",
    "# Calculate approximate target values\n",
    "arousal_df['arousal_value'] = arousal_df[arousal_features].mean(axis=1)\n",
    "valence_df['valence_value'] = valence_df[valence_features].mean(axis=1)\n",
    "\n",
    "# Prepare training and test data\n",
    "X_arousal = arousal_df[arousal_features]\n",
    "y_arousal = arousal_df['arousal_value']\n",
    "X_valence = valence_df[valence_features]\n",
    "y_valence = valence_df['valence_value']\n",
    "\n",
    "X_arousal_train, X_arousal_test, y_arousal_train, y_arousal_test = train_test_split(X_arousal, y_arousal, test_size=0.2, random_state=42)\n",
    "X_valence_train, X_valence_test, y_valence_train, y_valence_test = train_test_split(X_valence, y_valence, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Randomized Search for arousal model\n",
    "rf_arousal = RandomForestRegressor(random_state=42)\n",
    "random_search_arousal = RandomizedSearchCV(\n",
    "    rf_arousal, param_distributions=param_dist, n_iter=50, cv=3, random_state=42, scoring='neg_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "random_search_arousal.fit(X_arousal_train, y_arousal_train)\n",
    "best_rf_arousal = random_search_arousal.best_estimator_\n",
    "\n",
    "# Evaluate tuned arousal model\n",
    "y_arousal_pred = best_rf_arousal.predict(X_arousal_test)\n",
    "arousal_mse = mean_squared_error(y_arousal_test, y_arousal_pred)\n",
    "arousal_mae = mean_absolute_error(y_arousal_test, y_arousal_pred)\n",
    "arousal_r2 = r2_score(y_arousal_test, y_arousal_pred)\n",
    "print(f\"Tuned Arousal Model MSE: {arousal_mse}, MAE: {arousal_mae}, R²: {arousal_r2}\")\n",
    "\n",
    "# Randomized Search for valence model\n",
    "rf_valence = RandomForestRegressor(random_state=42)\n",
    "random_search_valence = RandomizedSearchCV(\n",
    "    rf_valence, param_distributions=param_dist, n_iter=50, cv=3, random_state=42, scoring='neg_mean_squared_error', n_jobs=-1\n",
    ")\n",
    "random_search_valence.fit(X_valence_train, y_valence_train)\n",
    "best_rf_valence = random_search_valence.best_estimator_\n",
    "\n",
    "# Evaluate tuned valence model\n",
    "y_valence_pred = best_rf_valence.predict(X_valence_test)\n",
    "valence_mse = mean_squared_error(y_valence_test, y_valence_pred)\n",
    "valence_mae = mean_absolute_error(y_valence_test, y_valence_pred)\n",
    "valence_r2 = r2_score(y_valence_test, y_valence_pred)\n",
    "print(f\"Tuned Valence Model MSE: {valence_mse}, MAE: {valence_mae}, R²: {valence_r2}\")\n",
    "\n",
    "# Save the best models\n",
    "joblib.dump(best_rf_arousal, \"./model/tuned_rf_arousal_model.pkl\")\n",
    "joblib.dump(best_rf_valence, \"./model/tuned_rf_valence_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe369e44-4ca3-42de-8a0d-57575e0fe77c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_rf_arousal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m mse_arousal, mse_valence\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save the best models\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(\u001b[43mbest_rf_arousal\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model/rf_arousal_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(best_rf_valence, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model/rf_valence_model.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'best_rf_arousal' is not defined"
     ]
    }
   ],
   "source": [
    "# Re-import necessary libraries due to session context reset\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Load data\n",
    "arousal_data = pd.read_csv('./data/song_arousal_summary.csv')\n",
    "valence_data = pd.read_csv('./data/song_valence_summary.csv')\n",
    "\n",
    "# Define selected features based on previous RFE results\n",
    "selected_rfe_arousal_features = ['pcm_RMSenergy_sma_stddev', 'F0final_sma_stddev', 'F0final_sma_amean',\n",
    "                                 'voicingFinalUnclipped_sma_stddev', 'pcm_fftMag_spectralFlux_sma_amean']\n",
    "\n",
    "selected_rfe_valence_features = ['F0final_sma_stddev', 'F0final_sma_amean', 'voicingFinalUnclipped_sma_stddev',\n",
    "                                 'pcm_fftMag_spectralCentroid_sma_amean', 'pcm_fftMag_spectralRollOff50.0_sma_stddev']\n",
    "\n",
    "# Generate placeholder target variables for demonstration\n",
    "np.random.seed(0)\n",
    "arousal_target = np.random.rand(len(arousal_data))  # Placeholder for arousal target\n",
    "valence_target = np.random.rand(len(valence_data))  # Placeholder for valence target\n",
    "\n",
    "# Split data into train and test sets for both arousal and valence\n",
    "X_train_arousal, X_test_arousal, y_train_arousal, y_test_arousal = train_test_split(\n",
    "    arousal_data[selected_rfe_arousal_features], arousal_target, test_size=0.2, random_state=0)\n",
    "\n",
    "X_train_valence, X_test_valence, y_train_valence, y_test_valence = train_test_split(\n",
    "    valence_data[selected_rfe_valence_features], valence_target, test_size=0.2, random_state=0)\n",
    "\n",
    "# Train RandomForestRegressor models for arousal and valence\n",
    "rf_arousal_model = RandomForestRegressor(random_state=0)\n",
    "rf_arousal_model.fit(X_train_arousal, y_train_arousal)\n",
    "\n",
    "rf_valence_model = RandomForestRegressor(random_state=0)\n",
    "rf_valence_model.fit(X_train_valence, y_train_valence)\n",
    "\n",
    "# Predictions and MSE calculations\n",
    "arousal_predictions = rf_arousal_model.predict(X_test_arousal)\n",
    "valence_predictions = rf_valence_model.predict(X_test_valence)\n",
    "\n",
    "mse_arousal = mean_squared_error(y_test_arousal, arousal_predictions)\n",
    "mse_valence = mean_squared_error(y_test_valence, valence_predictions)\n",
    "\n",
    "mse_arousal, mse_valence\n",
    "\n",
    "# Save the best models\n",
    "# Save the trained models for future use\n",
    "joblib.dump(rf_arousal_model, '/data/rf_arousal_model.pkl')\n",
    "joblib.dump(rf_valence_model, '/data/rf_valence_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8200e1-0989-479b-b158-a3b89ab34969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
