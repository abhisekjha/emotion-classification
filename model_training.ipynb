{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c659b7-13a7-484a-b1ee-d4a0ab606d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   song_id  sample_15000ms  sample_15500ms  sample_16000ms  sample_16500ms  \\\n",
       " 0        2       -0.109386       -0.114942       -0.116413       -0.118613   \n",
       " 1        3       -0.110846       -0.123973       -0.131103       -0.135956   \n",
       " 2        4        0.222327        0.179446        0.178388        0.184056   \n",
       " 3        5       -0.255613       -0.251579       -0.251958       -0.251124   \n",
       " 4        7        0.464234        0.460789        0.460991        0.461046   \n",
       " \n",
       "    sample_17000ms  sample_17500ms  sample_18000ms  sample_18500ms  \\\n",
       " 0       -0.126457       -0.133199       -0.136855       -0.144713   \n",
       " 1       -0.140775       -0.144664       -0.163118       -0.165218   \n",
       " 2        0.176042        0.178720        0.176345        0.175793   \n",
       " 3       -0.250763       -0.251957       -0.251957       -0.251957   \n",
       " 4        0.457240        0.465702        0.471809        0.469918   \n",
       " \n",
       "    sample_19000ms  ...  sample_622000ms  sample_622500ms  sample_623000ms  \\\n",
       " 0       -0.138985  ...              NaN              NaN              NaN   \n",
       " 1       -0.158858  ...              NaN              NaN              NaN   \n",
       " 2        0.176154  ...              NaN              NaN              NaN   \n",
       " 3       -0.251957  ...              NaN              NaN              NaN   \n",
       " 4        0.473377  ...              NaN              NaN              NaN   \n",
       " \n",
       "    sample_623500ms  sample_624000ms  sample_624500ms  sample_625000ms  \\\n",
       " 0              NaN              NaN              NaN              NaN   \n",
       " 1              NaN              NaN              NaN              NaN   \n",
       " 2              NaN              NaN              NaN              NaN   \n",
       " 3              NaN              NaN              NaN              NaN   \n",
       " 4              NaN              NaN              NaN              NaN   \n",
       " \n",
       "    sample_625500ms  sample_626000ms  sample_626500ms  \n",
       " 0              NaN              NaN              NaN  \n",
       " 1              NaN              NaN              NaN  \n",
       " 2              NaN              NaN              NaN  \n",
       " 3              NaN              NaN              NaN  \n",
       " 4              NaN              NaN              NaN  \n",
       " \n",
       " [5 rows x 1225 columns],\n",
       "    song_id  sample_15000ms  sample_15500ms  sample_16000ms  sample_16500ms  \\\n",
       " 0        2       -0.073341       -0.074661       -0.074077       -0.078154   \n",
       " 1        3       -0.189702       -0.187765       -0.183740       -0.188761   \n",
       " 2        4        0.154286        0.148063        0.146956        0.151180   \n",
       " 3        5        0.149053        0.148260        0.147369        0.146956   \n",
       " 4        7        0.342816        0.345193        0.332023        0.328887   \n",
       " \n",
       "    sample_17000ms  sample_17500ms  sample_18000ms  sample_18500ms  \\\n",
       " 0       -0.081588       -0.080873       -0.083611       -0.082145   \n",
       " 1       -0.193704       -0.190834       -0.189041       -0.197554   \n",
       " 2        0.135942        0.076832        0.084487        0.088513   \n",
       " 3        0.147857        0.146927        0.145651        0.145795   \n",
       " 4        0.327603        0.329011        0.327883        0.334822   \n",
       " \n",
       "    sample_19000ms  ...  sample_621500ms  sample_622000ms  sample_622500ms  \\\n",
       " 0       -0.081632  ...              NaN              NaN              NaN   \n",
       " 1       -0.202871  ...              NaN              NaN              NaN   \n",
       " 2        0.090944  ...              NaN              NaN              NaN   \n",
       " 3        0.146420  ...              NaN              NaN              NaN   \n",
       " 4        0.328447  ...              NaN              NaN              NaN   \n",
       " \n",
       "    sample_623000ms  sample_623500ms  sample_624000ms  sample_624500ms  \\\n",
       " 0              NaN              NaN              NaN              NaN   \n",
       " 1              NaN              NaN              NaN              NaN   \n",
       " 2              NaN              NaN              NaN              NaN   \n",
       " 3              NaN              NaN              NaN              NaN   \n",
       " 4              NaN              NaN              NaN              NaN   \n",
       " \n",
       "    sample_625000ms  sample_625500ms  sample_626000ms  \n",
       " 0              NaN              NaN              NaN  \n",
       " 1              NaN              NaN              NaN  \n",
       " 2              NaN              NaN              NaN  \n",
       " 3              NaN              NaN              NaN  \n",
       " 4              NaN              NaN              NaN  \n",
       " \n",
       " [5 rows x 1224 columns])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the arousal and valence CSV files to inspect their contents\n",
    "arousal_df = pd.read_csv('./data/annotations/arousal.csv')\n",
    "valence_df = pd.read_csv('./data/annotations/valence.csv')\n",
    "\n",
    "# Display the first few rows of each file to understand the data structure\n",
    "arousal_df.head(), valence_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b91a15be-cadc-41cf-b9aa-799a006fae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   arousal_mean  arousal_median  arousal_std  valence_mean  valence_median  \\\n",
       " 0     -0.197517       -0.164383     0.060047     -0.215511       -0.242763   \n",
       " 1     -0.193187       -0.173634     0.042909     -0.265855       -0.283232   \n",
       " 2      0.243072        0.261933     0.056383      0.155210        0.166481   \n",
       " 3     -0.236207       -0.235395     0.009459      0.140160        0.133046   \n",
       " 4      0.376292        0.344691     0.054167      0.332455        0.334178   \n",
       " \n",
       "    valence_std  \n",
       " 0     0.101869  \n",
       " 1     0.045872  \n",
       " 2     0.046598  \n",
       " 3     0.022091  \n",
       " 4     0.013138  ,\n",
       " array([-0.19751742, -0.19318693,  0.24307227, -0.23620671,  0.37629202]),\n",
       " array([-0.2155107 , -0.26585485,  0.15520962,  0.14015958,  0.33245465]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean, median, and standard deviation of samples for each song in both arousal and valence dataframes\n",
    "arousal_features = arousal_df.iloc[:, 1:].agg(['mean', 'median', 'std'], axis=1)\n",
    "valence_features = valence_df.iloc[:, 1:].agg(['mean', 'median', 'std'], axis=1)\n",
    "\n",
    "# Combine these statistics into a single feature set\n",
    "features = pd.concat([arousal_features, valence_features], axis=1)\n",
    "features.columns = ['arousal_mean', 'arousal_median', 'arousal_std', \n",
    "                    'valence_mean', 'valence_median', 'valence_std']\n",
    "\n",
    "# Extract the target labels (arousal and valence mean values) for model training\n",
    "y_arousal = arousal_features['mean'].values  # Target for arousal\n",
    "y_valence = valence_features['mean'].values  # Target for valence\n",
    "\n",
    "# Display the processed feature set and target arrays\n",
    "features.head(), y_arousal[:5], y_valence[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a45e224c-ec1e-4c5a-92fa-5ddd4d114f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arousal MSE: 4.4580093385233504e-06, Valence MSE: 0.048523434095012224\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "\n",
    "# Assuming you have `arousal.csv` and `valence.csv` data files\n",
    "# with one song per row and multiple time-sample columns\n",
    "arousal_df = pd.read_csv('./data/annotations/arousal.csv')\n",
    "valence_df = pd.read_csv('./data/annotations/valence.csv')\n",
    "\n",
    "# Extract mean, median, and std of arousal and valence values as new labels\n",
    "arousal_mean = arousal_df.iloc[:, 1:].mean(axis=1)\n",
    "valence_mean = valence_df.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "# Prepare features with only 3 values for each song (mean values for tempo, energy, and spectral centroid)\n",
    "def extract_features_for_training(df):\n",
    "    features = []\n",
    "    for _, row in df.iterrows():\n",
    "        tempo = np.mean(row[1:])\n",
    "        energy = np.sum(row[1:] ** 2) / len(row[1:])\n",
    "        spectral_centroid = np.mean(row[1:])\n",
    "        features.append([tempo, energy, spectral_centroid])\n",
    "    return np.array(features)\n",
    "\n",
    "# Extract features and labels\n",
    "X = extract_features_for_training(arousal_df)  # Feature matrix\n",
    "y_arousal = arousal_mean.values  # Arousal labels\n",
    "y_valence = valence_mean.values  # Valence labels\n",
    "\n",
    "# Split data for training and testing\n",
    "X_train, X_test, y_train_arousal, y_test_arousal = train_test_split(X, y_arousal, test_size=0.2, random_state=42)\n",
    "X_train, X_test, y_train_valence, y_test_valence = train_test_split(X, y_valence, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Random Forest models for arousal and valence prediction with the 3 features\n",
    "rf_arousal = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_arousal.fit(X_train, y_train_arousal)\n",
    "\n",
    "rf_valence = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_valence.fit(X_train, y_train_valence)\n",
    "\n",
    "# Evaluate models using Mean Squared Error (MSE)\n",
    "arousal_pred = rf_arousal.predict(X_test)\n",
    "valence_pred = rf_valence.predict(X_test)\n",
    "\n",
    "arousal_mse = mean_squared_error(y_test_arousal, arousal_pred)\n",
    "valence_mse = mean_squared_error(y_test_valence, valence_pred)\n",
    "\n",
    "# Save the trained models\n",
    "joblib.dump(rf_arousal, \"./model/rf_arousal_model_3_features.pkl\")\n",
    "joblib.dump(rf_valence, \"./model/rf_valence_model_3_features.pkl\")\n",
    "\n",
    "print(f\"Arousal MSE: {arousal_mse}, Valence MSE: {valence_mse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e05bff-524a-4ca2-9623-ebb55127eb48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
